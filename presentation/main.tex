%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

\documentclass[10pt,usenames,dvipsnames]{beamer}

\mode<presentation> {

% The Beamer class comes with a number of default slide themes
% which change the colors and layouts of slides. Below this is a list
% of all the themes, uncomment each in turn to see what they look like.

%\usetheme{default}
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
%\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

% As well as themes, the Beamer class has a number of color themes
% for any slide theme. Uncomment each of these in turn to see how it
% changes the colors of your current slide theme.

%\usecolortheme{albatross}
%\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{listings}
%\usepackage[usenames,dvipsnames]{xcolor}

\graphicspath{{../figures/}}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title[DDP Presentation]{Exploring Data Security on Microprocessor Hardware} % The short title appears at the bottom of every slide, the full title is only on the title page

\author{Meet Udeshi\\
14D070007\\
Supervisor: Prof. Virendra Singh} % Your name
\institute[CADSL] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
CADSL - IIT Bombay % Your institution for the title page
}
\date{\today} % Date, can be changed to a custom date

\begin{document}
\colorlet{LightBlue}{SkyBlue!50!}
\lstset{basicstyle=\tiny,backgroundcolor=\color{LightBlue}}

\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}


%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------
% : Simultaneous transformation, frame-wise transformation, loop migration, live variable optimisation
%------------------------------------------------
\section{Introduction}
%------------------------------------------------

%\subsection{Subsection Example} % A subsection can be created just before a set of slides with a common theme to further break down your presentation into chunks

\begin{frame}
\frametitle{Introduction}
\begin{itemize}
    \item Multi-thread, multi-core hardware focus on sharing computing resources
        among different programs.
    \item In cloud computing, technologies like virtual machines and virtual environments
        are allowing multiple different programs to share the same computing resources.
    \item Programs running on current hardware inevitably leave fingerprints of
        their execution in power traces, EMI spectrum,
        caches, etc.\footnote{\cite{side_channel_intro}}
    \item Attackers with the right knowledge and tools can leverage hardware
        implementation flaws in the design of these shared resources
        to extract data from a victim process via undetectable side-channels.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Contents} % Table of contents slide, comment this block out to remove it
\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}
%------------------------------------------------
\section{Side channels}

\begin{frame}
\frametitle{Side Channels}

Shared resources of the processor can leak information about the tasks being performed in it.
Measuring cache hit/miss, time of execution, power consumption, EMI spikes can
determine what part of code is running or what data is being processed.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{side_channel}
    \caption[Data leakage sources]{A number of side channels which are capable of leaking data.}
\end{figure}
\end{frame}

\subsection{Data dependent execution}
\begin{frame}[fragile]
\frametitle{Data dependent execution}

\begin{columns}[t]
    \column{0.49\textwidth}
        \textbf{Fast exponentiation algorithm used in RSA\footnote[frame]{\cite{cache_missing}}}
        \begin{lstlisting}[language={C}]
while(key > 0) {
    e = key % 2;

    Square();
    Reduce();
    if(e == 1) {
        Multiply();
        Reduce();
    }

    key >>= 1;
}
        \end{lstlisting}
    \column{0.49\textwidth}
        \textbf{S-box access used in AES\footnote[frame]{\cite{bern}}}
        \begin{lstlisting}[language={C}]
for(i=0; i<9; i++) {
    x = k;
    y = k ^ n;

    e = {S[x[1]]^1,
         S[x[2]],
         S[x[3]],
         S[x[0]]};
}
// Just for last round
y[0] = S[y[0]]^S[y[1]]^
       S[y[2]]^S[y[3]]^
        x[0];
        \end{lstlisting}
\end{columns}
\end{frame}

\subsection{Cache side channels}
\begin{frame}
\frametitle{Cache Side Channel}
\begin{enumerate}
    % \item Threads running in a single core use the same L1 caches. Processes on different cores of the same multi-core chip share L2 and L3 caches.
    \item Determine the cache-line accessed by victim using contention in shared cache.
    \item In set-associative cache design, that reveals a few bits of the address.
    \item For publicly available encryption libraries (OpenSSL), determine memory region of victim accesses.
    \item Using both these information, we can pinpoint exact address accessed by victim.
\end{enumerate}
\end{frame}

\begin{frame}
\frametitle{Prime+Probe}
\begin{figure}
\includegraphics[width=\textwidth]{prime_probe}
\caption{Working of Prime+Probe attack}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Flush+Reload}
\begin{figure}
\includegraphics[width=\textwidth]{flush_reload}
\caption{Working of Flush+Reload attack}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Flush+Reload on LLC}

\begin{columns}[c]
\column{0.6\textwidth}
\begin{figure}
\includegraphics[width=\textwidth]{flush_reload_crossvm}
\caption{Flush+Reload Attack via LLC}
\end{figure}

\column{0.39\textwidth}
    \begin{itemize}
        \item Virtual Machine environments are extensively used in cloud-computing
        \item VMs share a common host OS which perform page de-duplication.
        \item This allows VMs to share memory pages
        \item Enables hardware based side channels\footnote[frame]{\cite{cross_vm}}.
    \end{itemize}
\end{columns}
\end{frame}

%\subsection{Cache side channels on GPGPU}
\begin{frame}
\frametitle{Cache side channels on GPGPU}
\begin{itemize}
\item Nvidia GPGPUs recently started to support concurrent kernel execution at SM level
\item In this shared context, side channels can be exploited.
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{gpgpu}
    \caption{Memory layout of GPGPUs}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{GPGPU covert channel}
Naghibijouybari et al\footnote{\cite{naghi}} achieve communication speed of over 4Mbps
using a combination of L1 cache contention and SFU contention as covert channels.
They use the inherent parallelism in GPGPUs to open parallel communication channels on
each SM.
\vspace{0.5in}
\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{covert_channel}
    \caption{Covert channel implementation on GPGPU}
\end{figure}
\end{frame}

\section{Reverse engineering implementation}
\begin{frame}[fragile]
\frametitle{Reverse engineer cache parameters}
\begin{itemize}
    \item Knowing cache parameters is necessary for mounting any kind of side channel
        attacks on caches.
    \item Implemented CPU benchmarking based on the GPU microbenchmarking by
        Wong et al\footnote{\cite{wong}}.
    \item Stride access pattern over an array triggers a predictable number
        of cache-misses.
\end{itemize}

\begin{lstlisting}[caption={Generate array of given size with fixed stride pattern},language={C}]
size_t* array; // malloc beforehand
size_t t;

for (int i=0; i<array_size; i++) {
    t = i + STRIDE:
    if(t >= array_size) t %= STRIDE;
    array[i] = (size_t)array + sizeof(size_t)*t;
}
\end{lstlisting}

\end{frame}


\begin{frame}[fragile]
\frametitle{Reverse engineering cache parameters}
For measuring timing of the array access, \texttt{rdtsc} instruction is used to get a reading of the Time Stamp Counter before
and after accessing the array.

\begin{lstlisting}[caption={Timing measurement of stride access over the entire array},language={C}]
long start = __rdtsc();
size_t* next_ptr = &array[0];
for(int i=0; i<MAX_ITERS; i++) {
    next_ptr = *((size_t**)next_ptr);
}
long time = __rdtsc() - start;
\end{lstlisting}
\end{frame}

\begin{frame}
\frametitle{Result Plots}
Setup: GEM5 x86 atomic CPU. L1 data cache 1KB, 2-way, 64B line size.
\begin{figure}
\includegraphics[width=\textwidth]{reverse_eng_1kb}
\caption{Latency vs Array Size plot}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Result Plots}
Setup: GEM5 x86 atomic CPU. L1 data cache 16KB, 4-way, 64B line size.
\begin{figure}
\includegraphics[width=\textwidth]{reverse_eng_16kb}
\caption{Latency vs Array Size plot}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Result Plots}
Setup: Intel Skylake x86\_64 i5-6500. L1 data cache 32KB, 8-way, 64B line size.
\begin{figure}
\includegraphics[width=\textwidth]{reverse_eng_32kb}
\caption{Latency vs Array Size plot}
\end{figure}
\end{frame}

\section{Mitigations against Cache side channel}

\begin{frame}
\frametitle{Mitigations against cache side channel}
\begin{itemize}
    \item Change the implementation of each encryption algorithm to avoid leaks.
    \item Only possible for known attacks and unavoidable for any software to not leave fingerprint in shared resources.
    \item Change hardware design of caches so that one process doesn’t affect other processes via its cache accesses in a predictable way.
    \item Intentionally pollute cache to add noise in side channel measurements.
\end{itemize}
\end{frame}

%\subsection{Partition-locked cache}

%    \begin{frame}
%\frametitle{Partition-Locked cache}
%Naive cache partitioning would equally split cache for all threads.
%    Such a partitioned cache will let only one process access a single partition at a time \footnote{\cite{part_cache}}.
%    Wang et al have proposed a dynamically partitioned cache in \footnote{\cite{wang}}.
%PLCache requires addition of special locked-load/store instructions to the ISA.
%This also means OS has to look over
%which process gets to use them as a fairness measure.
%\end{frame}

%\subsection{Random-permutation cache}

\begin{frame}
\frametitle{Improved cache designs}
\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{pl-cache}
\caption{Partition-Locked cache - single cache line}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{rp-cache}
\caption{Random-permutation cache}
\end{figure}
\end{frame}

%\subsection{Context Sensitive Decoding}
\begin{frame}
\frametitle{Context Sensitive Decoding}
Taram et al\footnote{\cite{csd}} implement a custom decoder which can insert decoy
instructions to improve security.
\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{csd}
\caption{Custom decoder for Context Sensitive Decoding}
\end{figure}
Decoy instructions pollute the cache by running decoy loads and
disrupt attackers attempting side channel attacks on the cache.
\end{frame}

%\subsection{Disruptive prefetching}
\begin{frame}
\frametitle{Disruptive Prefetching}
\begin{itemize}
\item Fuchs et al\footnote{\cite{disruptive_prefetch}} introduce additional steps to the pre-fetchers to increase the randomness
in the loaded memory address.
\item Randomise the pattern sequence and degree to intentionally pollute the cache with unnecessary data.
\item Slightly degrades the performance of non-malicious programs, but terribly disrupt side channel.
\item Prime+Probe attack will not know whether the victim or the pre-fetcher evicted its block.
\item Flush+Reload would get false cache hits which were not caused by the victim.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Disruptive Prefetching}
\begin{figure}
\centering
\includegraphics[width=0.65\textwidth]{disruptive_prefetch}
\caption{Disruptive Prefetching}
\end{figure}
\end{frame}

\section{Attack on Prefetcher}

\begin{frame}
\frametitle{Disabling Prefetcher to avoid Cache Pollution}
\begin{itemize}
    \item Cache side-channels work by extracting information about cache
        accesses of victim process
    \item Any other process or hardware block which accesses the cache will
        increase noise in the side-channel
    \item We propose to disable the prefetcher by not allowing it to learn the stride patterns
    \item This can be done by running a third process in parallel which makes
        random loads at PC which alias with victim process' load PCs
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Disabling Prefetcher to avoid Cache Pollution}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.65\textwidth]{prefetch_attack}
    \caption{Prevent prefetcher from issuing memory accesses}
    \label{fig:prefetch_attack}
\end{figure}
\end{frame}

%\subsection{Full Attacker}

\begin{frame}
\frametitle{Prefetcher attack implementation}
\begin{itemize}
    \item Place load instructions at multiple PC address to fill up the prefetcher table
    \item Randomize stride for every load address
    \item Restrict load address to single cache line by keeping stride less than 64 bytes
    \item Ensure cache miss every time by flushing before load using \texttt{clflush}
    \item Use \texttt{nop} instructions to align loads to desired PC address
    \vspace{2em}
    \item Drawback: targets whole prefetcher and not few entries relevant to victim.
        Makes the attack slower and allows prefetcher to train on victim's accesses.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Assembly for Full Attacker}
\begin{lstlisting}[caption={Assembly showing load misses at different PCs},
label={lst:full_attack}]
00000000000006ca <attack>:
 6ce:   8b 58 36        mov    0x36(rax),ebx
 6d1:   90              nop
 6d2:   0f ae 78 36     clflush 0x36(rax)
 6d6:   8b 58 08        mov    0x8(rax),ebx
 6d9:   90              nop
 6da:   0f ae 78 08     clflush 0x8(rax)
 6de:   8b 58 3f        mov    0x3f(rax),ebx
 6e1:   90              nop
 6e2:   0f ae 78 3f     clflush 0x3f(rax)
 6e6:   8b 58 38        mov    0x38(rax),ebx
 6e9:   90              nop
 6ea:   0f ae 78 38     clflush 0x38(rax)
 6ee:   8b 58 20        mov    0x20(rax),ebx
 6f1:   90              nop
\end{lstlisting}
\end{frame}

%\subsection{Targeted Attacker}

\begin{frame}
\frametitle{Targeted Attacker}
\begin{itemize}
    \item Simulate victim process with random inputs and look at memory access patterns.
    \item Identify load addresses of the victim which have high probability
        of generating prefetches. These PCs will be target of the attack.
    \item Load instructions in the attacker are placed at PCs which alias with the target
        PCs of the victim. Remaining gaps are filled with \texttt{nop}.
    \item This attacker runs faster and is able to prevent the victim from successfully
        training the prefetcher.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Assembly for Targeted Attacker}
\begin{lstlisting}[caption={Attacker targeting specific PC addresses},
label={lst:targeted_attack}]
00000000000006ca <attack>:
 6da:   8b 58 0f          mov    0xf(rax),ebx
 6dd:   0f ae 78 0f       clflush 0xf(rax)
 6e1:   90                nop
 6e2:   90                nop
 6e3:   90                nop
 6e4:   8b 58 3c          mov    0x3c(rax),ebx
 6e7:   0f ae 78 3c       clflush 0x3c(rax)
 6eb:   90                nop
 6ec:   90                nop
     <nop slide> ...
 6f7:   90                nop
 6f8:   8b 58 2f          mov    0x2f(rax),ebx
 6fb:   0f ae 78 2f       clflush 0x2f(rax)
 6ff:   90                nop
\end{lstlisting}
\end{frame}

%\subsection{Results}

\begin{frame}[fragile]
\frametitle{Simulator Setup}

Victim process runs on core1 and attacker runs on core2. Number of prefetches
issued are measured for every 1,000,000 instructions of victim process.\\
\vspace{0.1in}
\begin{table}[hbp]
\centering
\begin{tabular}{|l|r|}
    \hline
    Simulator  & gem5 X86\\
    \hline
    Core Type  & O3 CPUs 8-wide fetch\\
    \hline
    Number of Cores & 2\\
    \hline
    L1 Icache & 32K 8-way\\
    \hline
    L1 Dcache & 32K 8-way\\
    \hline
    L2 cache & 256K 16-way shared between cores\\
    \hline
    L2 prefetcher  & Stride 64-entry 4-way, confidence threshold 4\\
    \hline
\end{tabular}
\\
\caption{Simulation setup}
\label{tab:simulation_setup}
\end{table}
\end{frame}


\begin{frame}
\frametitle{Results for benchmarks}
\begin{columns}[t]
    \column{0.74\textwidth}
        \begin{figure}[ht]
            \centering
            \includegraphics[width=0.8\textwidth]{hwpf_num}
            \caption{Number of prefetches issued on benchmarks}
        \end{figure}
    \column{0.25\textwidth}
    \\
    The drawback of the full attacker is apparent here where it is not able to fully reduce
    the number of prefetches to 0.
\end{columns}
\end{frame}

\begin{frame}
\frametitle{Results for AES victim}
The targeted attacker is able to successfully reduce the prefetches to nearly 0.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\textwidth]{pf_issued}
    \caption{Number of prefetches issued under three execution conditions: no attacker, full attacker, targeted attacker}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Results for AES victim}
This figure explains how the attacker is able to reduce the number of prefetches by decreasing
confidence of the prefetcher. It does not indicate how the targeted attacker is able to perform
better than full attacker.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\textwidth]{avg_conf}
    \caption{Average confidence of prefetcher entries}
    \label{fig:prefetch_attack}
\end{figure}
\end{frame}


\begin{frame}
\frametitle{Results for AES victim}
This figure shows the major reduction in prefetcher table hits for targeted attacker which
explains why it can perform better.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.75\textwidth]{pf_hits}
    \caption{Hits/Misses comparision for prefetcher table under three execution conditions}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Results for GHB Prefetcher}
The stride prefetcher was replaced with a GHB prefetcher implementation
using Delta Correlating Prediction Tables (DCPT).
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\textwidth]{dcpt-hwpf}
    \caption{Prefetches issued with DCPT Prefetcher}
\end{figure}
\end{frame}

\section{ROB based Side Channel}
\begin{frame}
\frametitle{Hypothetical ROB based Side Channel}
\begin{itemize}
    \item Reorder buffer is used by Out-of-Order cores for in-order retirement.
    \item In SMT cores, fairness policy ensures that roughly equal instructions are retired for all threads to maintain equal IPC.
    \item Simple implementation is to share retire pipeline width equally among threads.
    \item But when one thread is stalled, other thread will use full pipeline width to retire.
    \item IPC of other threads will see a slight increase.
    \item Data-dependent branch misses and cache misses can be infered from IPC information.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Hypothetical ROB based Side Channel}
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{rob_side_channel}
\caption{Reorder buffer for SMT. When T1 is stalled T2 retires twice as many instructions.}
\end{figure}
\end{frame}

\section{Conclusion}
\begin{frame}
\frametitle{Conclusion}
\begin{itemize}
    \item Modern hardware features have introduced leakages in the processor which is a security concern.
    \item GPGPUs are being targeted as a new domain of security leaks.
    \item Hardware design needs to take into account these kind of security leaks.
    \item Attacks to disable prefetcher are possible and may help enhance side-channels
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Future Scope}
\begin{itemize}
        \item Test prefetch attacker with Disruptive Prefetcher implementation.
        \item Create an attacker tailored for GHB instead of reusing stride attacker.
        \item Create a viable attack which can test and exploit ROB side-channel
\end{itemize}
\end{frame}

\begin{frame}
\Huge{\centerline{The End}}
\end{frame}

\begin{frame}[allowframebreaks]
\frametitle<presentation>{For Further Reading}

\begin{thebibliography}{10}
\bibitem[D. Page, Theoretical Use of Cache Memory as a Cryptanalytic Side-Channel]{cache_side_channel}
Theoretical Use of Cache Memory as a Cryptanalytic Side-Channel
, D. Page, Department of Computer Science, University of Bristol

\bibitem[C. Percival, Cache missing for fun and profit]{cache_missing}
Cache Missing for Fun and Profit, Colin Percival

\bibitem[D. J. Bernstien, Cache-timing attacks on AES]{bern}
Cache-timing attacks on AES, D.J. Bernstien

\bibitem[Chenglu Jin, Side Channel Attacks]{side_channel_intro}
Side Channel Attacks, Chenglu Jin, Department of Electrical \& Computer Engineering, University of Connecticut

\bibitem[Wait a minute! A fast, Cross-VM attack on AES - RAID'14]{cross_vm}
Gorka Irazoqui, Mehmet Sinan Inci, Thomas Eisenbarth, Berk Sunar, Wait a minute! A fast, Cross-VM attack on AES

\bibitem[D. Page - Partitioned Cache Architecture as a Side-Channel Defence Mechanism]{part_cache}
D. Page, {\it Partitioned Cache Architecture as a Side-Channel Defence Mechanism}

\bibitem[New Cache Designs for Thwarting Software Cache-based Side Channel Attacks - ISCA'07]{wang}
Z. Wang and R. B. Lee, New Cache Designs for Thwarting Software Cache-based Side Channel Attacks, ISCA'07

\bibitem[A novel cache architecture with enhanced performance and security - MICRO'08]{newcache}
Z. Wang and R. B. Lee. A novel cache architecture with enhanced performance and security. In Proceedings of the 41st Annual Inter­national Symposium on Microarchitecture, MICRO 2008

\bibitem[Disruptive prefetching: impact on side-channel attacks and cache designs - SYSTOR'15]{disruptive_prefetch}
Adi Fuchs and Ruby B. Lee. 2015. Disruptive prefetching: impact on side-channel attacks and cache designs. In Proceedings of the 8th ACM International Systems and Storage Conference (SYSTOR '15)

\bibitem[Constructing and characterizing covert channels on GPGPUs - MICRO-50]{naghi}
Hoda Naghibijouybari, Khaled N. Khasawneh, and Nael Abu-Ghazaleh. Constructing and characterizing covert channels on GPGPUs - MICRO'50

\bibitem[Demystifying GPU microarchitecture through microbenchmark - ISPASS]{wong}
Henry Wong, M. M. Papadopoulou, Maryam Sadooghi-Alvandi, and Andreas Moshovos. 2010. Demystifying GPU microarchitecture through microbenchmark - ISPASS'10

\bibitem[Mobilizing the Micro-Ops: Exploiting Context Sensitive Decoding for Security and Energy Efficiency - ISCA'18]{csd}
Mohammadkazem Taram, Ashish Venkat, Dean Tullsen, Mobilizing the Micro-Ops: Exploiting Context Sensitive Decoding for Security and Energy Efficiency - ISCA'18

\bibitem{stride_pf}
J. W. C. Fu, J. H. Patel and B. L. Janssens, {\it Stride Directed Prefetching In Scalar Processors}, [1992] Proceedings the 25th Annual International Symposium on Microarchitecture MICRO 25

\bibitem{gem5}
The gem5 Simulator. Nathan Binkert, Bradford Beckmann, Gabriel Black, Steven K. Reinhardt, Ali Saidi, Arkaprava Basu, Joel Hestness, Derek R. Hower, Tushar Krishna, Somayeh Sardashti, Rathijit Sen, Korey Sewell, Muhammad Shoaib, Nilay Vaish, Mark D. Hill, and David A. Wood. May 2011, ACM SIGARCH Computer Architecture News.

\bibitem{gem5-stride}
http://www.gem5.org/docs/html/stride\_8cc\_source.html

\bibitem{gem5-dcpt}
https://github.com/gem5/gem5/blob/master/src/mem/cache/prefetch/delta\_correlating\_prediction\_tables.cc

\bibitem{dcpt}
Storage efficient hardware prefetching using delta-correlating prediction tables, M Grannaes, M Jahre, L Natvig - Journal of Instruction-Level Parallelism, 2011
\end{thebibliography}
\end{frame}

%----------------------------------------------------------------------------------------

\end{document}
